Multinomial Naive Bayes using unigrams:
                       0            1
chicago      0.052720848 0.0241368286
location     0.005229682 0.0169437340
smell        0.007491166 0.0007992327
luxury       0.006925795 0.0004795396
decided      0.008621908 0.0022378517
recently     0.007632509 0.0017583120
finally      0.013992933 0.0059143223
millennium   0.005371025 0.0006393862
great        0.006219081 0.0188618926
seemed       0.011024735 0.0039961637
rude         0.010742049 0.0062340153
experience   0.015971731 0.0087915601
cleaned      0.005512367 0.0014386189
open         0.001272085 0.0068734015
smelled      0.006501767 0.0020780051
room         0.113356890 0.1062979540
wait         0.008904594 0.0055946292
star         0.001837456 0.0083120205
morning      0.007067138 0.0081521739
many         0.003674912 0.0094309463
hotel        0.104734982 0.0983056266
arrived      0.014134276 0.0083120205
make         0.010883392 0.0068734015
sheets       0.005088339 0.0028772379
elevator     0.001272085 0.0057544757
floor        0.005229682 0.0140664962
website      0.006219081 0.0028772379
manager      0.003957597 0.0079923274
found        0.012579505 0.0067135550
comfortable  0.001554770 0.0059143223
called       0.010035336 0.0172634271
service      0.028268551 0.0292519182
ready        0.006077739 0.0022378517
suites       0.004240283 0.0012787724
like         0.023462898 0.0179028133
hours        0.005936396 0.0038363171
took         0.011024735 0.0068734015
clerk        0.007915194 0.0031969309
conference   0.001696113 0.0063938619
food         0.009328622 0.0057544757
pool         0.003816254 0.0068734015
smoke        0.004946996 0.0017583120
hilton       0.007632509 0.0047953964
requested    0.004240283 0.0054347826
cant         0.001272085 0.0046355499
desk         0.022897527 0.0233375959
got          0.016395760 0.0139066496
bar          0.004664311 0.0083120205
expected     0.005936396 0.0033567775
staying      0.011590106 0.0078324808
car          0.002968198 0.0051150895
went         0.013851590 0.0081521739
first        0.014558304 0.0129475703
bed          0.013710247 0.0207800512
day          0.008904594 0.0169437340
walk         0.001554770 0.0051150895
towels       0.007773852 0.0039961637
need         0.002544170 0.0065537084
charge       0.002968198 0.0076726343
small        0.005371025 0.0113491049
hour         0.008339223 0.0051150895
travel       0.001413428 0.0049552430
coffee       0.002544170 0.0065537084
door         0.006501767 0.0115089514
place        0.011307420 0.0073529412
reviews      0.001413428 0.0044757033
old          0.002544170 0.0070332481
check        0.011448763 0.0091112532
find         0.008339223 0.0063938619
call         0.005088339 0.0115089514
now          0.001978799 0.0057544757
recommend    0.006925795 0.0039961637
reserved     0.003816254 0.0020780051
suite        0.004946996 0.0046355499
put          0.002685512 0.0059143223
rate         0.001696113 0.0052749361
close        0.001837456 0.0047953964
late         0.003109541 0.0041560102
around       0.008480565 0.0051150895
street       0.001837456 0.0057544757
high         0.005088339 0.0043158568
internet     0.004805654 0.0067135550
wife         0.007067138 0.0035166240
problem      0.002402827 0.0054347826
said         0.006925795 0.0116687980
night        0.018657244 0.0255754476
money        0.008339223 0.0060741688
wrong        0.004664311 0.0022378517
ive          0.002261484 0.0054347826
reservations 0.003533569 0.0027173913
wall         0.001696113 0.0044757033
lobby        0.007632509 0.0131074169
know         0.004946996 0.0055946292
spend        0.004381625 0.0019181586
looked       0.009045936 0.0059143223
extra        0.004522968 0.0030370844
phone        0.005088339 0.0099104859
restaurant   0.004381625 0.0055946292
disappointed 0.007773852 0.0067135550
staff        0.019787986 0.0254156010
line         0.002120141 0.0054347826
overall      0.005936396 0.0047953964
dont         0.005512367 0.0103900256
better       0.010176678 0.0129475703
offer        0.004098940 0.0038363171
bathroom     0.011590106 0.0142263427

CONFUSION MATRIX:
naive.bayes.predictions.unigrams.mi  0  1
                                  0 66 11
                                  1 14 69
[1] "ACCURACY:  0.84375"
[1] "PRECISION:  0.825"
[1] "RECALL: 0.857142857142857"
[1] "F1: 0.840764331210191"

------------------------------------------------------------------------
Multinomial Naive Bayes using bigrams:
                        0            1
chicago       0.044462987 0.0202711773
location      0.004410538 0.0142300980
smell         0.006317797 0.0006712310
luxury        0.005840982 0.0004027386
hotel.chicago 0.006198593 0.0009397235
chicago.hotel 0.005840982 0.0008054772
decided       0.007271427 0.0018794469
recently      0.006437001 0.0014767083
finally       0.011801168 0.0049671097
millennium    0.004529741 0.0005369848
great         0.005244964 0.0158410525
seemed        0.009297890 0.0033561552
rude          0.009059483 0.0052356021
experience    0.013470020 0.0073835414
cleaned       0.004648945 0.0012082159
open          0.001072833 0.0057725869
smelled       0.005483371 0.0017452007
room          0.095601383 0.0892737280
wait          0.007509834 0.0046986173
star          0.001549648 0.0069808028
morning       0.005960186 0.0068465566
many          0.003099297 0.0079205262
hotel         0.088329956 0.0825614176
arrived       0.011920372 0.0069808028
make          0.009178686 0.0057725869
sheets        0.004291334 0.0024164317
elevator      0.001072833 0.0048328635
floor         0.004410538 0.0118136663
website       0.005244964 0.0024164317
manager       0.003337704 0.0067123104
found         0.010609131 0.0056383407
comfortable   0.001311241 0.0049671097
called        0.008463464 0.0144985904
service       0.023840744 0.0245670560
ready         0.005125760 0.0018794469
suites        0.003576112 0.0010739697
like          0.019787817 0.0150355752
hours         0.005006556 0.0032219090
took          0.009297890 0.0057725869
clerk         0.006675408 0.0026849242
conference    0.001430445 0.0053698483
food          0.007867445 0.0048328635
pool          0.003218500 0.0057725869
smoke         0.004172130 0.0014767083
hilton        0.006437001 0.0040273862
requested     0.003576112 0.0045643711
cant          0.001072833 0.0038931400
desk          0.019311003 0.0195999463
got           0.013827631 0.0116794201
bar           0.003933723 0.0069808028
expected      0.005006556 0.0028191704
staying       0.009774705 0.0065780642
car           0.002503278 0.0042958786
went          0.011681964 0.0068465566
first         0.012277983 0.0108739428
bed           0.011562761 0.0174520070
day           0.007509834 0.0142300980
got.room      0.003814519 0.0020136931
walk          0.001311241 0.0042958786
towels        0.006556205 0.0033561552
need          0.002145667 0.0055040945
charge        0.002503278 0.0064438180
small         0.004529741 0.0095314807
hour          0.007033019 0.0042958786
travel        0.001192037 0.0041616324
coffee        0.002145667 0.0055040945
door          0.005483371 0.0096657269
place         0.009536298 0.0061753255
reviews       0.001192037 0.0037588938
old           0.002145667 0.0059068331
check         0.009655501 0.0076520338
find          0.007033019 0.0053698483
call          0.004291334 0.0096657269
now           0.001668852 0.0048328635
recommend     0.005840982 0.0033561552
reserved      0.003218500 0.0017452007
suite         0.004172130 0.0038931400
put           0.002264871 0.0049671097
rate          0.001430445 0.0044301248
close         0.001549648 0.0040273862
late          0.002622482 0.0034904014
around        0.007152223 0.0042958786
street        0.001549648 0.0048328635
high          0.004291334 0.0036246476
internet      0.004052926 0.0056383407
wife          0.005960186 0.0029534166
problem       0.002026463 0.0045643711
said          0.005840982 0.0097999732
night         0.015734891 0.0214793932
money         0.007033019 0.0051013559
wrong         0.003933723 0.0018794469
ive           0.001907260 0.0045643711
reservations  0.002980093 0.0022821855
room.service  0.006913816 0.0072492952
wall          0.001430445 0.0037588938
lobby         0.006437001 0.0110081890
know          0.004172130 0.0046986173
spend         0.003695315 0.0016109545
looked        0.007629038 0.0049671097
extra         0.003814519 0.0025506779
phone         0.004291334 0.0083232649
restaurant    0.003695315 0.0046986173
disappointed  0.006556205 0.0056383407
staff         0.016688521 0.0213451470
line          0.001788056 0.0045643711
overall       0.005006556 0.0040273862
dont          0.004648945 0.0087260035
better        0.008582668 0.0108739428
offer         0.003456908 0.0032219090
bathroom      0.009774705 0.0119479125
checked       0.007748242 0.0056383407
guests        0.003218500 0.0067123104
come          0.002503278 0.0046986173
wifi          0.003576112 0.0034904014
front.desk    0.014066039 0.0135588670
nothing       0.006317797 0.0069808028
front         0.015258076 0.0157068063
try           0.002145667 0.0046986173
available     0.006079390 0.0038931400
two           0.008821075 0.0134246208
cold          0.004529741 0.0026849242
horrible      0.002980093 0.0014767083
told          0.008225057 0.0135588670
though        0.005960186 0.0052356021
minutes       0.009417094 0.0081890187
second        0.001788056 0.0044301248
reservation   0.008463464 0.0093972345
bad           0.006913816 0.0063095718
never         0.009536298 0.0146328366
weekend       0.006317797 0.0044301248

CONFUSION MATRIX:
naive.bayes.predictions.unigrams.mi  0  1
                                  0 66 11
                                  1 14 69
[1] "ACCURACY:  0.84375"
[1] "PRECISION:  0.825"
[1] "RECALL: 0.857142857142857"
[1] "F1: 0.840764331210191"

------------------------------------------------------------------------
Logistic regression using unigrams:

reviews.logreg.pred  0  1
                  0 57  8
                  1 23 72
[1] "ACCURACY:  0.80625"
[1] "PRECISION:  0.7125"
[1] "RECALL: 0.876923076923077"
[1] "F1: 0.786206896551724"
[1] 0.02368937

------------------------------------------------------------------------
Logistic regression using bigrams:

CONFUSION MATRIX:            
reviews.logreg.pred  0  1
                  0 51  8
                  1 29 72
[1] "ACCURACY:  0.76875"
[1] "PRECISION:  0.6375"
[1] "RECALL: 0.864406779661017"
[1] "F1: 0.733812949640288"
[1] 0.01875

------------------------------------------------------------------------
Classification tree using unigrams:

Variables actually used in tree construction:
 [1] able        actually    air         almost      already     also        although    another    
 [9] anything    area        around      arrived     asked       back        bad         bar        
[17] bathroom    beds        better      big         carpet      charge      check       chicago    
[25] coffee      comfortable conference  couldnt     decided     desk        didnt       dirty      
[33] door        elevator    every       expected    far         finally     first       found      
[41] friendly    good        great       guest       guests      hard        hotel       husband    
[49] internet    ive         last        lobby       location    long        looked      many       
[57] money       much        need        new         offered     old         one         pay        
[65] person      rate        really      received    recently    reviews     rooms       said       
[73] several     sheets      smell       someone     spend       star        still       terrible   
[81] toilet      told        try         wasnt       water       website     will       

Root node error: 320/640 = 0.5

n= 640 

          CP nsplit rel error  xerror     xstd
1  0.4093750      0  1.000000 1.08125 0.039398
2  0.0343750      1  0.590625 0.59063 0.036064
3  0.0312500      2  0.556250 0.60313 0.036282
4  0.0250000      3  0.525000 0.59063 0.036064
5  0.0187500      4  0.500000 0.56875 0.035664
6  0.0156250      6  0.462500 0.56563 0.035605
7  0.0125000      8  0.431250 0.55625 0.035423
8  0.0093750      9  0.418750 0.54688 0.035238
9  0.0062500     15  0.362500 0.60000 0.036228
10 0.0049107     38  0.215625 0.63750 0.036840
11 0.0046875     46  0.175000 0.65000 0.037028
12 0.0031250     49  0.159375 0.65000 0.037028
13 0.0015625     91  0.028125 0.67500 0.037383
14 0.0000000    109  0.000000 0.69375 0.037629

CONFUSION MATRIX:
reviews.rpart.pred  0  1
                 0 48 23
                 1 32 57
[1] "ACCURACY:  0.65625"
[1] "PRECISION:  0.6"
[1] "RECALL: 0.676056338028169"
[1] "F1: 0.635761589403973"
[1] 0.01875

------------------------------------------------------------------------
Classification tree using bigrams:

Variables actually used in tree construction:
 [1] able        air         almost      already     also        another     anyone      anything   
 [9] area        around      arrived     asked       back        bad         bar         bathroom   
[17] beds        better      big         carpet      charge      check       chicago     coffee     
[25] comfortable conference  couldnt     decided     desk        dirty       door        elevator   
[33] every       expected    finally     first       found       front       given       good       
[41] great       guest       guests      hard        hotel       internet    ive         last       
[49] lobby       location    looked      many        money       much        need        night      
[57] offered     old         one         pay         person      rate        really      received   
[65] recently    reviews     rooms       said        several     sheets      smell       someone    
[73] spend       star        stay        still       toilet      told        try         upon       
[81] wasnt       water       will        will.never 

Root node error: 320/640 = 0.5

n= 640 

          CP nsplit rel error  xerror     xstd
1  0.4093750      0  1.000000 1.08125 0.039398
2  0.0343750      1  0.590625 0.59063 0.036064
3  0.0312500      2  0.556250 0.60313 0.036282
4  0.0250000      3  0.525000 0.59063 0.036064
5  0.0187500      4  0.500000 0.56875 0.035664
6  0.0156250      6  0.462500 0.56563 0.035605
7  0.0125000      8  0.431250 0.55625 0.035423
8  0.0093750      9  0.418750 0.54688 0.035238
9  0.0062500     15  0.362500 0.60313 0.036282
10 0.0049107     38  0.215625 0.64062 0.036888
11 0.0046875     46  0.175000 0.65938 0.037165
12 0.0031250     49  0.159375 0.65313 0.037074
13 0.0015625     93  0.021875 0.64688 0.036982
14 0.0000000    107  0.000000 0.66250 0.037209

CONFUSION MATRIX:               
reviews.rpart.pred  0  1
                 0 48 23
                 1 32 57
[1] "ACCURACY:  0.65625"
[1] "PRECISION:  0.6"
[1] "RECALL: 0.676056338028169"
[1] "F1: 0.635761589403973"

------------------------------------------------------------------------
Random forest using unigrams:

mtry = 17  OOB error = 18.75% 
Searching left ...
mtry = 9 	OOB error = 17.34% 
0.075 0.05 
mtry = 5 	OOB error = 18.44% 
-0.06306306 0.05 
Searching right ...
mtry = 34 	OOB error = 18.91% 
-0.09009009 0.05 
       mtry  OOBError
5.OOB     5 0.1843750
9.OOB     9 0.1734375
17.OOB   17 0.1875000
34.OOB   34 0.1890625
[1] 9
[1] 519

CONFUSION MATRIX:                
random.forests.predictions  0  1
                         0 14  3
                         1 66 77
[1] "ACCURACY:  0.56875"
[1] "PRECISION:  0.175"
[1] "RECALL: 0.823529411764706"
[1] "F1: 0.288659793814433"

------------------------------------------------------------------------
Random forest using bigrams:

mtry = 17  OOB error = 17.19% 
Searching left ...
mtry = 9 	OOB error = 17.5% 
-0.01818182 0.05 
Searching right ...
mtry = 34 	OOB error = 19.84% 
-0.1545455 0.05 
       mtry  OOBError
9.OOB     9 0.1750000
17.OOB   17 0.1718750
34.OOB   34 0.1984375
[1] 17
[1] 850

CONFUSION MATRIX:
random.forests.predictions  0  1
                         0 13  3
                         1 67 77
[1] "ACCURACY:  0.5625"
[1] "PRECISION:  0.1625"
[1] "RECALL: 0.8125"
[1] "F1: 0.270833333333333"

------------------------------------------------------------------------
McNemar's Chi-squared tests with continuity correction:

Multinomial Naive Bayes vs. Logistic regression, both using unigrams.
McNemar's chi-squared = 0.96154, df = 1, p-value = 0.3268

Multinomial Naive Bayes vs. Logistic regression, both using bigrams.
McNemar's chi-squared = 3.375, df = 1, p-value = 0.06619

Random forest vs. Multinomial Naive Bayes, both using unigrams.
McNemar's chi-squared = 28.015, df = 1, p-value = 1.204e-07

Random forest vs. Logistic regression, both using unigrams.
McNemar's chi-squared = 26.327, df = 1, p-value = 2.882e-07

Random forest vs. Multinomial Naive Bayes, both using bigrams.
McNemar's chi-squared = 28.918, df = 1, p-value = 7.551e-08

Random forest vs. Logistic regression, both using bigrams.
McNemar's chi-squared = 22.756, df = 1, p-value = 1.84e-06

Classification tree using unigrams vs. Classification tree using bigrams
McNemar's chi-squared = NaN, df = 1, p-value = NA

Random forests using unigrams vs. Random forests using bigrams
McNemar's chi-squared = 0, df = 1, p-value = 1

Logistic regression using unigrams vs. Logistic regression using bigrams
McNemar's chi-squared = 4.1667, df = 1, p-value = 0.04123

Multinomial Naive Bayes using unigrams vs. Multinomial Naive Bayes using bigrams 
McNemar's chi-squared = 0.25, df = 1, p-value = 0.6171